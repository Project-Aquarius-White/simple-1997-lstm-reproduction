# Long Lag Problem - Experiment 2c
# Reference: Section 5.2 "Experiment 2" (Hochreiter & Schmidhuber, 1997)
#
# Task: Reproduce a short sequence after a long delay
# Input: Short pattern followed by distractor sequence
# Output: Reproduce the original pattern
#
# Maximum delay version (p=1000) - "largest time lags"

experiment:
  name: "long_lag_2c"
  task: "long_lag"
  description: "Long lag problem - maximum lag variant (p=1000)"

# Sequence parameters (Section 5.2)
# Experiment 2c: p=1000 (maximum delay tested)
data:
  pattern_length: 1          # Single element to remember
  delay: 1000                # p=1000 distractor steps
  num_samples: 1024000       # More training for hardest variant
  num_test_samples: 10240    # Test sequences
  distractor_symbols: 4      # Distractor alphabet size

# Training hyperparameters (Section 5.2)
# Careful tuning needed for extreme lag
training:
  num_epochs: 1              # Single pass (online learning)
  learning_rate: 0.01        # Very low LR for extreme lag
  batch_size: 1              # Online learning

# Network architecture
network:
  input_size: 6              # Pattern + distractor symbols (one-hot)
  hidden_size: 1             # 1 memory cell block
  output_size: 2             # Binary output (0 or 1)

# Weight initialization (Section 5.2)
# "weights in range [-0.2, 0.2]"
initialization:
  init_range: [-0.2, 0.2]

# Gate biases
gate_biases:
  input_gate: -6.0           # Maximum bias for maximum lag
  output_gate: 0.0
